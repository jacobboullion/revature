# PROJECT 1

## Project Description

This project takes in large amounts of wikipedia page view and clickstream data in order to answer some questions and do analysis based on this data.

## Technologies Used

* Hive 
* YARN
* MapReduce
* HDFS
* DBeaver

## Features

List of features ready and TODOs for future development
* Loads data from local directory
* Makes tables for the csv data collected locally 
* Queries run on these tables and get information

To-do list:
* Take data from hdfs
* Simplify number of Queries

## Getting Started
   
(include git clone command)
(include all environment setup steps)
* git clone the repo
* install hdfs, yarn, and hive
* start hive server with command: hiveserver2
* You can connect to the server using a program like DBeaver or in beeline using: beeline -u jdbc:hive2://localhost:10000
* Once your connected you can start using the HQL queries in the provided script 

## Usage

> You can run the queries like this 

## Contributors

> Here list the people who have contributed to this project. (ignore this section, if its a solo project)

## License

This project uses the following license: [<license_name>](<link>).
